HloModule train_step_pipeshard_parallel_mesh_0.47-0_apply_grad, entry_computation_layout={(f32[128]{0},f32[128,128]{1,0},f32[128]{0},f32[128,128]{1,0},s32[],f32[128]{0},f32[128,128]{1,0},f32[128]{0},f32[128,128]{1,0},s32[],f32[128]{0},f32[128,128]{1,0},f32[128]{0},f32[128,128]{1,0})->(f32[128]{0}, f32[128,128]{1,0}, f32[128]{0}, f32[128,128]{1,0}, s32[], /*index=5*/f32[128]{0}, f32[128,128]{1,0}, f32[128]{0}, f32[128,128]{1,0}, s32[])}

ENTRY %main.318-0_apply_grad (param_0: f32[128], param_1: f32[128,128], param_2: f32[128], param_3: f32[128,128], param_4: s32[], param_5: f32[128], param_6: f32[128,128], param_7: f32[128], param_8: f32[128,128], param_9: s32[], param_10: f32[128], param_11: f32[128,128], param_12: f32[128], param_13: f32[128,128]) -> (f32[128], f32[128,128], f32[128], f32[128,128], s32[], /*index=5*/f32[128], f32[128,128], f32[128], f32[128,128], s32[]) {
  %param_10 = f32[128]{0} parameter(10), sharding={devices=[2,2]0,2,1,3 last_tile_dim_replicate}, metadata={op_name="0_apply_grad$start"}
  %constant = f32[] constant(0.5), sharding={replicated}
  %broadcast = f32[128]{0} broadcast(f32[] %constant), dimensions={}, sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/div"}
  %multiply = f32[128]{0} multiply(f32[128]{0} %param_10, f32[128]{0} %broadcast), sharding={devices=[4]0,2,1,3}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/div"}
  %param_0 = f32[128]{0} parameter(0), sharding={devices=[4]0,2,1,3}, metadata={op_name="0_apply_grad$start"}
  %constant.17 = f32[] constant(0.9), sharding={replicated}
  %broadcast.20 = f32[128]{0} broadcast(f32[] %constant.17), dimensions={}, sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/mul" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/transform.py" source_line=70}
  %multiply.237 = f32[128]{0} multiply(f32[128]{0} %param_0, f32[128]{0} %broadcast.20), sharding={devices=[4]0,2,1,3}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/mul" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/transform.py" source_line=70}
  %add.238 = f32[128]{0} add(f32[128]{0} %multiply, f32[128]{0} %multiply.237), sharding={devices=[4]0,2,1,3}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/add" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/transform.py" source_line=70}
  %param_11 = f32[128,128]{1,0} parameter(11), sharding={devices=[1,2,2]0,2,1,3 last_tile_dim_replicate}, metadata={op_name="0_apply_grad$start"}
  %broadcast.1 = f32[128,128]{1,0} broadcast(f32[] %constant), dimensions={}, sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/div"}
  %multiply.1 = f32[128,128]{1,0} multiply(f32[128,128]{1,0} %param_11, f32[128,128]{1,0} %broadcast.1), sharding={devices=[2,2]0,1,2,3}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/div"}
  %param_1 = f32[128,128]{1,0} parameter(1), sharding={devices=[2,2]0,1,2,3}, metadata={op_name="0_apply_grad$start"}
  %broadcast.18 = f32[128,128]{1,0} broadcast(f32[] %constant.17), dimensions={}, sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/mul" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/transform.py" source_line=70}
  %multiply.239 = f32[128,128]{1,0} multiply(f32[128,128]{1,0} %param_1, f32[128,128]{1,0} %broadcast.18), sharding={devices=[2,2]0,1,2,3}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/mul" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/transform.py" source_line=70}
  %add.240 = f32[128,128]{1,0} add(f32[128,128]{1,0} %multiply.1, f32[128,128]{1,0} %multiply.239), sharding={devices=[2,2]0,1,2,3}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/add" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/transform.py" source_line=70}
  %param_12 = f32[128]{0} parameter(12), sharding={replicated}, metadata={op_name="0_apply_grad$start"}
  %multiply.2 = f32[128]{0} multiply(f32[128]{0} %param_12, f32[128]{0} %broadcast), sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/div"}
  %param_2 = f32[128]{0} parameter(2), sharding={replicated}, metadata={op_name="0_apply_grad$start"}
  %multiply.241 = f32[128]{0} multiply(f32[128]{0} %param_2, f32[128]{0} %broadcast.20), sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/mul" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/transform.py" source_line=70}
  %add.242 = f32[128]{0} add(f32[128]{0} %multiply.2, f32[128]{0} %multiply.241), sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/add" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/transform.py" source_line=70}
  %param_13 = f32[128,128]{1,0} parameter(13), sharding={devices=[2,1,2]0,2,1,3 last_tile_dim_replicate}, metadata={op_name="0_apply_grad$start"}
  %multiply.3 = f32[128,128]{1,0} multiply(f32[128,128]{1,0} %param_13, f32[128,128]{1,0} %broadcast.1), sharding={devices=[2,2]0,2,1,3}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/div"}
  %param_3 = f32[128,128]{1,0} parameter(3), sharding={devices=[2,2]0,2,1,3}, metadata={op_name="0_apply_grad$start"}
  %multiply.243 = f32[128,128]{1,0} multiply(f32[128,128]{1,0} %param_3, f32[128,128]{1,0} %broadcast.18), sharding={devices=[2,2]0,2,1,3}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/mul" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/transform.py" source_line=70}
  %add.244 = f32[128,128]{1,0} add(f32[128,128]{1,0} %multiply.3, f32[128,128]{1,0} %multiply.243), sharding={devices=[2,2]0,2,1,3}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/add" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/transform.py" source_line=70}
  %param_4 = s32[] parameter(4), sharding={replicated}, metadata={op_name="0_apply_grad$start"}
  %constant.26 = s32[] constant(2147483647), sharding={replicated}
  %compare.262 = pred[] compare(s32[] %param_4, s32[] %constant.26), direction=LT, sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/lt" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/numerics.py" source_line=118}
  %constant.25 = s32[] constant(1), sharding={replicated}
  %add.263 = s32[] add(s32[] %param_4, s32[] %constant.25), sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/add" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/numerics.py" source_line=118}
  %select.264 = s32[] select(pred[] %compare.262, s32[] %add.263, s32[] %constant.26), sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/select_n" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/numerics.py" source_line=118}
  %param_5 = f32[128]{0} parameter(5), sharding={devices=[2,2]0,2,1,3 last_tile_dim_replicate}, metadata={op_name="0_apply_grad$start"}
  %constant.30 = f32[] constant(1), sharding={replicated}
  %constant.33 = s32[] constant(0), sharding={replicated}
  %maximum.246 = s32[] maximum(s32[] %param_4, s32[] %constant.33), sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/max" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/schedule.py" source_line=86}
  %constant.32 = s32[] constant(10), sharding={replicated}
  %minimum.247 = s32[] minimum(s32[] %maximum.246, s32[] %constant.32), sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/min" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/schedule.py" source_line=86}
  %convert.248 = f32[] convert(s32[] %minimum.247), sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/convert_element_type[new_dtype=float32 weak_type=False]" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/schedule.py" source_line=87}
  %constant.4 = f32[] constant(0.1), sharding={replicated}
  %multiply.4 = f32[] multiply(f32[] %convert.248, f32[] %constant.4), sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/div" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/schedule.py" source_line=87}
  %subtract.250 = f32[] subtract(f32[] %constant.30, f32[] %multiply.4), sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/sub" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/schedule.py" source_line=87}
  %constant.29 = f32[] constant(0.00999), sharding={replicated}
  %multiply.251 = f32[] multiply(f32[] %subtract.250, f32[] %constant.29), sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/mul" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/schedule.py" source_line=88}
  %constant.28 = f32[] constant(1e-05), sharding={replicated}
  %add.252 = f32[] add(f32[] %multiply.251, f32[] %constant.28), sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/add" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/schedule.py" source_line=88}
  %constant.27 = f32[] constant(-1), sharding={replicated}
  %multiply.253 = f32[] multiply(f32[] %add.252, f32[] %constant.27), sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/mul" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/alias.py" source_line=37}
  %broadcast.254 = f32[128]{0} broadcast(f32[] %multiply.253), dimensions={}, sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/mul" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/transform.py" source_line=694}
  %multiply.255 = f32[128]{0} multiply(f32[128]{0} %broadcast.254, f32[128]{0} %add.238), sharding={devices=[4]0,2,1,3}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/mul" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/transform.py" source_line=694}
  %add.265 = f32[128]{0} add(f32[128]{0} %param_5, f32[128]{0} %multiply.255), sharding={devices=[4]0,2,1,3}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/add" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/update.py" source_line=43}
  %reshape.9 = f32[128]{0} reshape(f32[128]{0} %add.265), sharding={devices=[2,2]0,2,1,3 last_tile_dim_replicate}
  %param_6 = f32[128,128]{1,0} parameter(6), sharding={devices=[1,2,2]0,2,1,3 last_tile_dim_replicate}, metadata={op_name="0_apply_grad$start"}
  %broadcast.256 = f32[128,128]{1,0} broadcast(f32[] %multiply.253), dimensions={}, sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/mul" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/transform.py" source_line=694}
  %multiply.257 = f32[128,128]{1,0} multiply(f32[128,128]{1,0} %broadcast.256, f32[128,128]{1,0} %add.240), sharding={devices=[2,2]0,1,2,3}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/mul" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/transform.py" source_line=694}
  %add.266 = f32[128,128]{1,0} add(f32[128,128]{1,0} %param_6, f32[128,128]{1,0} %multiply.257), sharding={devices=[2,2]0,1,2,3}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/add" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/update.py" source_line=43}
  %reshape.7 = f32[128,128]{1,0} reshape(f32[128,128]{1,0} %add.266), sharding={devices=[1,2,2]0,2,1,3 last_tile_dim_replicate}
  %param_7 = f32[128]{0} parameter(7), sharding={replicated}, metadata={op_name="0_apply_grad$start"}
  %multiply.259 = f32[128]{0} multiply(f32[128]{0} %broadcast.254, f32[128]{0} %add.242), sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/mul" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/transform.py" source_line=694}
  %add.267 = f32[128]{0} add(f32[128]{0} %param_7, f32[128]{0} %multiply.259), sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/add" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/update.py" source_line=43}
  %param_8 = f32[128,128]{1,0} parameter(8), sharding={devices=[2,1,2]0,2,1,3 last_tile_dim_replicate}, metadata={op_name="0_apply_grad$start"}
  %multiply.261 = f32[128,128]{1,0} multiply(f32[128,128]{1,0} %broadcast.256, f32[128,128]{1,0} %add.244), sharding={devices=[2,2]0,2,1,3}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/mul" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/transform.py" source_line=694}
  %add.268 = f32[128,128]{1,0} add(f32[128,128]{1,0} %param_8, f32[128,128]{1,0} %multiply.261), sharding={devices=[2,2]0,2,1,3}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/add" source_file="/python3.9-env/lib/python3.9/site-packages/optax/_src/update.py" source_line=43}
  %reshape.11 = f32[128,128]{1,0} reshape(f32[128,128]{1,0} %add.268), sharding={devices=[2,1,2]0,2,1,3 last_tile_dim_replicate}
  %param_9 = s32[] parameter(9), sharding={replicated}, metadata={op_name="0_apply_grad$start"}
  %add.269 = s32[] add(s32[] %param_9, s32[] %constant.25), sharding={replicated}, metadata={op_name="parallelize(train_step_pipeshard_parallel_mesh_0)/jit(main)/add" source_file="/code/alpa/alpa/model/model_util.py" source_line=301}
  ROOT %tuple.16 = (f32[128]{0}, f32[128,128]{1,0}, f32[128]{0}, f32[128,128]{1,0}, s32[], /*index=5*/f32[128]{0}, f32[128,128]{1,0}, f32[128]{0}, f32[128,128]{1,0}, s32[]) tuple(f32[128]{0} %add.238, f32[128,128]{1,0} %add.240, f32[128]{0} %add.242, f32[128,128]{1,0} %add.244, s32[] %select.264, /*index=5*/f32[128]{0} %reshape.9, f32[128,128]{1,0} %reshape.7, f32[128]{0} %add.267, f32[128,128]{1,0} %reshape.11, s32[] %add.269), sharding={{devices=[4]0,2,1,3}, {devices=[2,2]0,1,2,3}, {replicated}, {devices=[2,2]0,2,1,3}, {replicated}, /*index=5*/{devices=[2,2]0,2,1,3 last_tile_dim_replicate}, {devices=[1,2,2]0,2,1,3 last_tile_dim_replicate}, {replicated}, {devices=[2,1,2]0,2,1,3 last_tile_dim_replicate}, {replicated}}, metadata={op_name="tuple.11"}
}

